{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q bitsandbytes datasets accelerate loralib\n!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n!pip install --upgrade accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-16T08:07:53.910412Z","iopub.execute_input":"2023-05-16T08:07:53.911109Z","iopub.status.idle":"2023-05-16T08:09:25.358333Z","shell.execute_reply.started":"2023-05-16T08:07:53.911080Z","shell.execute_reply":"2023-05-16T08:09:25.357150Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.12.0)\nCollecting accelerate\n  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\nSuccessfully installed accelerate-0.19.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:50:19.735790Z","iopub.execute_input":"2023-05-16T08:50:19.736420Z","iopub.status.idle":"2023-05-16T08:50:20.898442Z","shell.execute_reply.started":"2023-05-16T08:50:19.736384Z","shell.execute_reply":"2023-05-16T08:50:20.897290Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTue May 16 08:50:20 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   75C    P0    42W /  70W |  14310MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\nimport torch\nimport torch.nn as nn\nimport bitsandbytes as bnb\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"facebook/opt-6.7b\", \n    load_in_8bit=True, \n    device_map='auto',\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-6.7b\")","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:09:34.154103Z","iopub.execute_input":"2023-05-16T08:09:34.154686Z","iopub.status.idle":"2023-05-16T08:12:09.508357Z","shell.execute_reply.started":"2023-05-16T08:09:34.154641Z","shell.execute_reply":"2023-05-16T08:12:09.507262Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167ed2a53d4642cb979442d4cbbff238"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/41.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20e5325cb034a759c43a6fd99035de9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be6f197d64b444938b0aa634dd593514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5212e18c20b340d0822d038f73470da8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66276fa7163341f2a593e8d03512bdaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69142829bf54bfd9f81069d46d7310f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eebb50857c604609b78b3bb653b0a6b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca9267e05054409b81c20bf41da6341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64af1e27b78346d385ff6628408f08c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92dae31a52654037bb2ff24135688892"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46231a198e8b4d22858fcd3cf3a40a02"}},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:01.334781Z","iopub.execute_input":"2023-05-16T08:13:01.335174Z","iopub.status.idle":"2023-05-16T08:13:02.458645Z","shell.execute_reply.started":"2023-05-16T08:13:01.335145Z","shell.execute_reply":"2023-05-16T08:13:02.457399Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Tue May 16 08:13:02 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   50C    P0    27W /  70W |   8490MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# for param in model.parameters():\n#     param.requires_grad = False\n#     if param.ndim==1:\n#         param.data = param.data.to(torch.float32)\n\n# model.gradient_checkpointing_enable()\n# model.enable_input_require_grads()\n\n# class CastOutputToFloat(nn.Sequential):\n#     def forward(self,x):\n#         return super().forward(x).to(torch.float32)\n\n# model.lm_head = CastOutputToFloat(model.lm_head)\n\nfrom peft import prepare_model_for_int8_training\n\nmodel = prepare_model_for_int8_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:12:22.239374Z","iopub.execute_input":"2023-05-16T08:12:22.239767Z","iopub.status.idle":"2023-05-16T08:12:22.282985Z","shell.execute_reply.started":"2023-05-16T08:12:22.239732Z","shell.execute_reply":"2023-05-16T08:12:22.282178Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Apply LoRA","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model \n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:12:44.320376Z","iopub.execute_input":"2023-05-16T08:12:44.320786Z","iopub.status.idle":"2023-05-16T08:12:56.710180Z","shell.execute_reply.started":"2023-05-16T08:12:44.320749Z","shell.execute_reply":"2023-05-16T08:12:56.709066Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:11.095212Z","iopub.execute_input":"2023-05-16T08:13:11.095608Z","iopub.status.idle":"2023-05-16T08:13:11.108161Z","shell.execute_reply.started":"2023-05-16T08:13:11.095573Z","shell.execute_reply":"2023-05-16T08:13:11.107069Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"trainable params: 8388608 || all params: 6666862592 || trainable%: 0.12582542214183376\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndata = load_dataset(\"Abirate/english_quotes\")\ndata","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:20.523603Z","iopub.execute_input":"2023-05-16T08:13:20.523980Z","iopub.status.idle":"2023-05-16T08:13:22.480837Z","shell.execute_reply.started":"2023-05-16T08:13:20.523950Z","shell.execute_reply":"2023-05-16T08:13:22.479881Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/Abirate--english_quotes to /root/.cache/huggingface/datasets/json/Abirate--english_quotes-7ef692ccb59fbf2a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc0b84499ed479b84c66942cf145757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/647k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a39bca543e4b33a0e995d86666b9b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feb822a6f6234fa88d07350edf9c959d"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/Abirate--english_quotes-7ef692ccb59fbf2a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0006a1bd3dfe458dbec8a2ae7620b0d6"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['quote', 'author', 'tags'],\n        num_rows: 2508\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data = data.map(lambda samples: tokenizer(samples['quote']), batched=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:29.126983Z","iopub.execute_input":"2023-05-16T08:13:29.128404Z","iopub.status.idle":"2023-05-16T08:13:29.615060Z","shell.execute_reply.started":"2023-05-16T08:13:29.128359Z","shell.execute_reply":"2023-05-16T08:13:29.613940Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f124800f59cc4e5dbdee7a2b232f3cb9"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['quote', 'author', 'tags', 'input_ids', 'attention_mask'],\n        num_rows: 2508\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import transformers\n\nargs = transformers.TrainingArguments(per_device_train_batch_size=4, \n        gradient_accumulation_steps=4,\n        warmup_steps=100, \n        max_steps=200, \n        learning_rate=2e-4, \n        fp16=True,\n        logging_steps=1, \n        output_dir='outputs')\n\ndata_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\ntrainer = transformers.Trainer(model =model, train_dataset = data[\"train\"], args=args, data_collator=data_collator)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:33.604142Z","iopub.execute_input":"2023-05-16T08:13:33.604490Z","iopub.status.idle":"2023-05-16T08:13:34.330976Z","shell.execute_reply.started":"2023-05-16T08:13:33.604461Z","shell.execute_reply":"2023-05-16T08:13:34.329875Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:13:40.149206Z","iopub.execute_input":"2023-05-16T08:13:40.149575Z","iopub.status.idle":"2023-05-16T08:50:19.733900Z","shell.execute_reply.started":"2023-05-16T08:13:40.149547Z","shell.execute_reply":"2023-05-16T08:50:19.732894Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230516_081356-38tc8rmd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/thabet-chaawri/huggingface/runs/38tc8rmd' target=\"_blank\">eager-voice-6</a></strong> to <a href='https://wandb.ai/thabet-chaawri/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/thabet-chaawri/huggingface' target=\"_blank\">https://wandb.ai/thabet-chaawri/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/thabet-chaawri/huggingface/runs/38tc8rmd' target=\"_blank\">https://wandb.ai/thabet-chaawri/huggingface/runs/38tc8rmd</a>"},"metadata":{}},{"name":"stderr","text":"You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 35:39, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.364600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.201800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.300700</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.186400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.876400</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.305100</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.192200</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.445500</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.460100</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.019400</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.935300</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.929400</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.054000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.970100</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.012500</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.093000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.765000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.151400</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.400000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.123800</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.311900</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.907400</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.078800</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.942200</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.879500</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.927900</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.369500</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.974100</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2.054300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.916600</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.954800</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>2.196000</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2.002100</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>2.026400</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.576500</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.879800</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.821300</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.725100</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.994600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.702000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>2.130200</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>2.021600</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.698100</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.985500</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>2.048500</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>2.056900</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.763400</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>2.059700</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.746200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.875000</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>2.388800</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>2.498300</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>2.071700</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.807800</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.915700</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>2.170000</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>2.164900</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.929600</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.853000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.650600</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.614000</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>2.030100</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.823800</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.614400</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.923400</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>2.046100</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>2.117200</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.809800</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>1.861400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.860000</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>2.026600</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>1.861400</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>1.771500</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>1.836600</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.750600</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>1.892300</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>1.924600</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>2.321600</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>2.233400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.310400</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>1.950400</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>2.069600</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>1.919000</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>2.001000</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>1.955600</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>1.448700</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>1.784400</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>1.666700</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>1.902000</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.713200</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>2.301100</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>2.096500</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>2.319700</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>1.599300</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>1.737300</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>1.676000</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>1.607000</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>1.736800</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>2.275200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.954100</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>1.674300</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>1.653600</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>1.607100</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>1.846100</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>1.867900</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>1.951700</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>2.183300</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>1.632000</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>1.211400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.258300</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>1.831900</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>2.116200</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>2.131900</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>1.912600</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>1.582200</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>1.561800</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>1.736100</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>1.710400</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>1.723200</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.356500</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>2.062900</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>1.880300</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>1.855000</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>2.057300</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>2.152500</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>1.939500</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>2.094400</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>1.731300</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>2.111100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.889800</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>1.720300</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>2.070400</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>1.777900</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>1.960200</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>1.770900</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>1.960600</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>1.686000</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>1.981400</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>1.636800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.793600</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>1.957700</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>1.828600</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>2.047900</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>1.923100</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>1.778300</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>1.830800</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>1.359100</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>1.981400</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>1.763300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.216900</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>1.951800</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>2.418500</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>1.866200</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>2.481500</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>1.662100</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>2.045800</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>1.993500</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>2.109600</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>2.103900</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.494900</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>1.874100</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>1.964300</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>2.241100</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>1.999900</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>1.950700</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>1.967800</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>1.639200</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>1.814700</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>1.899200</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.836000</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>2.159200</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>1.731500</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>1.685900</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>2.018300</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>2.087900</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>1.717100</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>1.495700</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>2.106700</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>2.342900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.394900</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>1.893700</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>1.963500</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>1.175900</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>1.881000</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>2.131300</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>1.900000</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>1.658000</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>1.615500</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>1.869100</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.024500</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>1.973000</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>2.501800</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>1.957400</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>1.944500</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>1.965800</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>1.712600</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>1.862000</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>1.746900</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>1.947800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.574900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.9296385663747788, metrics={'train_runtime': 2199.5342, 'train_samples_per_second': 1.455, 'train_steps_per_second': 0.091, 'total_flos': 1.148636791701504e+16, 'train_loss': 1.9296385663747788, 'epoch': 1.28})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}